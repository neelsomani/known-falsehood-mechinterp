# Pairwise Activation Patching for Epistemic Stance

The previous ablation experiments identified a direction that linearly separates declared-true and declared-false statements at the end of the statement span, but removing this direction did not reliably affect downstream consequence selection. Further analysis showed that perturbations at the statement token did not mediate into the final decision representation, and even aggressive multi-layer ablations at the decision token could be compensated by later computation. This suggests that the stance signal used for consequence selection may not align with a single global probe direction across prompt formats or token positions.

To directly test whether epistemic stance is causally represented at the site that drives the model’s decision, we adopt a pairwise activation-patching approach. For each underlying consequence question, we construct two prompts that are identical except for epistemic stance (declared-true vs. declared-false). We run both prompts and capture the hidden state at a chosen layer and at the final prompt token, which is the representation from which the A/B logits are computed. We then perform a counterfactual intervention by overwriting the hidden state from one stance condition with the hidden state from the other, while keeping the prompt text fixed. If the model’s behavior shifts toward the patched stance, this provides direct causal evidence that the internal representation at that site mediates how epistemic stance influences downstream reasoning.

This approach avoids assumptions about global linear directions or cross-prompt alignment and instead tests the full high-dimensional representation induced by stance under identical conditions. Because the intervention is localized to a specific layer and token position and swaps only the internal state associated with epistemic stance, it constitutes a strong mechanistic test of whether stance is a causal control variable for premise-conditioned inference in the model.